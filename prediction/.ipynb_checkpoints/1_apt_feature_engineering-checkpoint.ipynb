{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import uuid\n",
    "\n",
    "\n",
    "\n",
    "#raw = pd.pandas.read_csv('../setup_data/pred_1x1_20181206.csv',sep=\",\",low_memory=False)\n",
    "raw = pd.pandas.read_csv('../20181220_raw_geo.csv',sep=\",\",low_memory=False)\n",
    "\n",
    "#https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data Set for variable calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5099\n"
     ]
    }
   ],
   "source": [
    "# copy raw data & create new base variables\n",
    "data = raw.copy()\n",
    "data['published_dt'] = pd.to_datetime(raw['published'])\n",
    "data['sold_dt'] = pd.to_datetime(raw['sold_date'])\n",
    "data['sqm_price_diff'] = data['sqm_sold_price'] - data['sqm_list_price']\n",
    "data['cnt'] = 1\n",
    "data = data[data['published'] >'2018-09-01']\n",
    "data['sqm_bin'] = pd.qcut(data['living_area'], 5) # generate sqm buckets\n",
    "data['uuid'] = [uuid.uuid4() for _ in range(len(data))]\n",
    "\n",
    "# choose vars needed for calculation\n",
    "# set important indexes\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "## Define functions that will be used in lambda functions for a dataset\n",
    "#######################################################################\n",
    "\n",
    "# Expanding window mean for a variable\n",
    "def expanding_mean_for_var(row,var_to_calc,historic_df):\n",
    "    var = historic_df[\n",
    "        (historic_df.index.get_level_values('published_dt') < row.name)\n",
    "    ][var_to_calc].mean()\n",
    "    return var\n",
    "\n",
    "# Expanding window mean for a variable in a group\n",
    "def expanding_mean_for_var_per_group(row,var_to_calc,historic_df,group):\n",
    "    var = historic_df[\n",
    "        (historic_df.index.get_level_values('published_dt') < row.name)\n",
    "        & (historic_df.index.get_level_values('area_from_geo') == row.name[1])\n",
    "    ][var_to_calc].mean()\n",
    "    return var\n",
    "\n",
    "\n",
    "def rolling_mean_for_var(row,var_to_calc,historic_df,days):\n",
    "    var = historic_df[\n",
    "       (historic_df.index.get_level_values('published_dt') < row.name)\n",
    "       & (historic_df.index.get_level_values('published_dt') > (row.name - pd.to_timedelta(days, unit='d')))\n",
    "    ][var_to_calc].mean()\n",
    "    return var\n",
    "\n",
    "\n",
    "# Rolling window mean for a variable in a group\n",
    "def rolling_mean_for_var_per_group(row,var_to_calc,historic_df,group,days):\n",
    "    var = historic_df[\n",
    "        (historic_df.index.get_level_values('published_dt') < row.name[0])\n",
    "       & (historic_df.index.get_level_values('published_dt') > (row.name[0] - pd.to_timedelta(days, unit='d')))\n",
    "        & (historic_df.index.get_level_values(group) == row.name[1])\n",
    "    ][var_to_calc].mean()\n",
    "    return var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate variables without group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 18.464281 sec\n"
     ]
    }
   ],
   "source": [
    "# Setup new dataset for purpose\n",
    "df_no_group = data[['uuid','published_dt','sqm_sold_price','sqm_price_diff','living_area','sqm_rent_price']].copy()\n",
    "df_no_group = df_no_group.set_index('published_dt')\n",
    "\n",
    "before = datetime.now()\n",
    "rolling_mean_sqm_price_90d = df_no_group.apply(lambda row: rolling_mean_for_var(row=row,var_to_calc='sqm_sold_price',historic_df=df_no_group,days=90),axis=1)\n",
    "rolling_mean_sqm_price_diff_90d = df_no_group.apply(lambda row: rolling_mean_for_var(row=row,var_to_calc='sqm_price_diff',historic_df=df_no_group,days=90),axis=1)\n",
    "rolling_mean_sqm_90d = df_no_group.apply(lambda row: rolling_mean_for_var(row=row,var_to_calc='living_area',historic_df=df_no_group,days=90),axis=1)\n",
    "rolling_mean_sqm_rent_90d = df_no_group.apply(lambda row: rolling_mean_for_var(row=row,var_to_calc='sqm_rent_price',historic_df=df_no_group,days=90),axis=1)\n",
    "\n",
    "after = datetime.now()\n",
    "print(\"run time: \"+str((after-before).total_seconds()) + \" sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate variables with groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 26.527661 sec\n"
     ]
    }
   ],
   "source": [
    "## AREA FROM GEO\n",
    "# Setup new dataset for purpose\n",
    "df_group_area = data[['uuid','published_dt','sqm_sold_price','sqm_price_diff','living_area','sqm_rent_price','area_from_geo']].copy()\n",
    "df_group_area = df_group_area.set_index(['published_dt','area_from_geo'])\n",
    "\n",
    "# only calculate for apts where more than top 20% apts in area\n",
    "geo_cnt_limit = 0.05*max(df_group_area.groupby('area_from_geo').sqm_sold_price.transform(len))\n",
    "df_group_area = df_group_area[df_group_area.groupby('area_from_geo').sqm_sold_price.transform(len) > geo_cnt_limit]\n",
    "\n",
    "before = datetime.now()\n",
    "df_group_area['rolling_mean_sqm_price_per_area_90d'] = df_group_area.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_sold_price',historic_df=df_group_area,group='area_from_geo',days=90),axis=1)\n",
    "df_group_area['rolling_mean_sqm_price_diff_per_area_90d'] = df_group_area.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_price_diff',historic_df=df_group_area,group='area_from_geo',days=90),axis=1)\n",
    "df_group_area['rolling_mean_sqm_per_area_90d'] = df_group_area.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='living_area',historic_df=df_group_area,group='area_from_geo',days=90),axis=1)\n",
    "df_group_area['rolling_mean_sqm_rent_per_area_90d'] = df_group_area.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_rent_price',historic_df=df_group_area,group='area_from_geo',days=90),axis=1)\n",
    "\n",
    "df_group_area = df_group_area.reset_index(drop=True)[['uuid','rolling_mean_sqm_price_per_area_90d','rolling_mean_sqm_price_diff_per_area_90d','rolling_mean_sqm_per_area_90d','rolling_mean_sqm_rent_per_area_90d']]\n",
    "df_group_area = df_group_area.set_index('uuid')\n",
    "after = datetime.now()\n",
    "print(\"run time: \"+str((after-before).total_seconds()) + \" sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 30.03395 sec\n"
     ]
    }
   ],
   "source": [
    "## SQM BIN\n",
    "# Setup new dataset for purpose\n",
    "df_group_sqm_bin = data[['uuid','published_dt','sqm_sold_price','sqm_price_diff','living_area','sqm_rent_price','sqm_bin']].copy()\n",
    "df_group_sqm_bin = df_group_sqm_bin.set_index(['published_dt','sqm_bin'])\n",
    "\n",
    "# only calculate for apts where more than top 20% apts in area\n",
    "geo_cnt_limit = 0.05*max(df_group_sqm_bin.groupby('sqm_bin').sqm_sold_price.transform(len))\n",
    "df_group_sqm_bin = df_group_sqm_bin[df_group_sqm_bin.groupby('sqm_bin').sqm_sold_price.transform(len) > geo_cnt_limit]\n",
    "\n",
    "before = datetime.now()\n",
    "df_group_sqm_bin['rolling_mean_sqm_price_per_sqm_bin_90d'] = df_group_sqm_bin.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_sold_price',historic_df=df_group_sqm_bin,group='sqm_bin',days=90),axis=1)\n",
    "df_group_sqm_bin['rolling_mean_sqm_price_diff_per_sqm_bin_90d'] = df_group_sqm_bin.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_price_diff',historic_df=df_group_sqm_bin,group='sqm_bin',days=90),axis=1)\n",
    "df_group_sqm_bin['rolling_mean_sqm_per_sqm_bin_90d'] = df_group_sqm_bin.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='living_area',historic_df=df_group_sqm_bin,group='sqm_bin',days=90),axis=1)\n",
    "df_group_sqm_bin['rolling_mean_sqm_rent_sqm_bin_90d'] = df_group_sqm_bin.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_rent_price',historic_df=df_group_sqm_bin,group='sqm_bin',days=90),axis=1)\n",
    "\n",
    "df_group_sqm_bin = df_group_sqm_bin.reset_index(drop=True)[['uuid','rolling_mean_sqm_price_per_sqm_bin_90d','rolling_mean_sqm_price_diff_per_sqm_bin_90d','rolling_mean_sqm_per_sqm_bin_90d','rolling_mean_sqm_rent_sqm_bin_90d']]\n",
    "df_group_sqm_bin = df_group_sqm_bin.set_index('uuid')\n",
    "after = datetime.now()\n",
    "print(\"run time: \"+str((after-before).total_seconds()) + \" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 26.110605 sec\n"
     ]
    }
   ],
   "source": [
    "## BROKER\n",
    "# Setup new dataset for purpose\n",
    "df_group_broker = data[['uuid','published_dt','sqm_sold_price','sqm_price_diff','living_area','sqm_rent_price','source_name']].copy()\n",
    "df_group_broker = df_group_broker.set_index(['published_dt','source_name'])\n",
    "\n",
    "# only calculate for apts where more than top 20% apts in area\n",
    "geo_cnt_limit = 0.05*max(df_group_broker.groupby('source_name').sqm_sold_price.transform(len))\n",
    "df_group_broker = df_group_broker[df_group_broker.groupby('source_name').sqm_sold_price.transform(len) > geo_cnt_limit]\n",
    "\n",
    "before = datetime.now()\n",
    "df_group_broker['rolling_mean_sqm_price_per_broker_90d'] = df_group_broker.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_sold_price',historic_df=df_group_broker,group='source_name',days=90),axis=1)\n",
    "df_group_broker['rolling_mean_sqm_price_diff_per_broker_90d'] = df_group_broker.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_price_diff',historic_df=df_group_broker,group='source_name',days=90),axis=1)\n",
    "df_group_broker['rolling_mean_sqm_per_broker_90d'] = df_group_broker.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='living_area',historic_df=df_group_broker,group='source_name',days=90),axis=1)\n",
    "df_group_broker['rolling_mean_sqm_rent_per_broker_90d'] = df_group_broker.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_rent_price',historic_df=df_group_broker,group='source_name',days=90),axis=1)\n",
    "\n",
    "df_group_broker = df_group_broker.reset_index(drop=True)[['uuid','rolling_mean_sqm_price_per_broker_90d','rolling_mean_sqm_price_diff_per_broker_90d','rolling_mean_sqm_per_broker_90d','rolling_mean_sqm_rent_per_broker_90d']]\n",
    "df_group_broker = df_group_broker.set_index('uuid')\n",
    "after = datetime.now()\n",
    "print(\"run time: \"+str((after-before).total_seconds()) + \" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data.copy()\n",
    "output = pd.merge(output,df_group_area,left_on = 'uuid', right_index = True, how = 'left')\n",
    "output = pd.merge(output,df_group_sqm_bin,left_on = 'uuid', right_index = True, how = 'left')\n",
    "output = pd.merge(output,df_group_broker,left_on = 'uuid', right_index = True, how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.loc[data['published_dt'] >'2016-04-01'][\n",
    "    ['published_dt'\n",
    "    ,'sqm_sold_price'\n",
    "    ,'rooms'\n",
    "    ,'floor'\n",
    "    ,'rent'\n",
    "    ,'living_area\n",
    "    ,'construction_year'\n",
    "    ,'distance_ocean'\n",
    "    ,'published_week'\n",
    "    ,'rolling_mean_sqm_price_diff_per_area_90d'\n",
    "    ,'rolling_mean_sqm_per_area_90d'\n",
    "    ,'rolling_mean_sqm_rent_per_area_90d'\n",
    "    ,'rolling_mean_sqm_price_per_sqm_bin_90d'\n",
    "    ,'rolling_mean_sqm_price_diff_per_sqm_bin_90d'\n",
    "    ,'rolling_mean_sqm_per_sqm_bin_90d'\n",
    "    ,'rolling_mean_sqm_rent_sqm_bin_90d'\n",
    "    ,'rolling_mean_sqm_price_per_broker_90d'\n",
    "    ,'rolling_mean_sqm_price_diff_per_broker_90d'\n",
    "    ,'rolling_mean_sqm_per_broker_90d'\n",
    "    ,'rolling_mean_sqm_rent_per_broker_90d'\n",
    "    ]\n",
    "]\n",
    "output.to_csv('featured_variables.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
