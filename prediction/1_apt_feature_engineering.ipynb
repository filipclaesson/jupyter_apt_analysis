{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import uuid\n",
    "\n",
    "\n",
    "\n",
    "#raw = pd.pandas.read_csv('../setup_data/pred_1x1_20181206.csv',sep=\",\",low_memory=False)\n",
    "raw = pd.pandas.read_csv('../20181220_raw_geo.csv',sep=\",\",low_memory=False)\n",
    "\n",
    "#https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data Set for variable calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'bool' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3912b7f8ece4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cnt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'published'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;34m'2018-09-01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sqm_bin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msqm_bins_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'living_area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# generate sqm buckets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uuid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36mqcut\u001b[0;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[1;32m    304\u001b[0m     fac, bins = _bins_to_cuts(x, bins, labels=labels,\n\u001b[1;32m    305\u001b[0m                               \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_lowest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                               dtype=dtype, duplicates=duplicates)\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     return _postprocess_for_cut(fac, bins, retbins, x_is_series,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x, bins, right, labels, precision, include_lowest, dtype, duplicates)\u001b[0m\n\u001b[1;32m    350\u001b[0m                                     dtype=dtype)\n\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                 raise ValueError('Bin labels must be one fewer than '\n\u001b[1;32m    354\u001b[0m                                  'the number of bin edges')\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'bool' has no len()"
     ]
    }
   ],
   "source": [
    "# copy raw data & create new base variables\n",
    "data = raw.copy()\n",
    "data['published_dt'] = pd.to_datetime(raw['published'])\n",
    "data['sold_dt'] = pd.to_datetime(raw['sold_date'])\n",
    "data['sqm_price_diff'] = data['sqm_sold_price'] - data['sqm_list_price']\n",
    "data['cnt'] = 1\n",
    "data = data[data['published'] >'2018-09-01']\n",
    "data['sqm_bin'],sqm_bins_list = pd.qcut(data['living_area'], 5,retbins=True,labels=) # generate sqm buckets\n",
    "data['uuid'] = [uuid.uuid4() for _ in range(len(data))]\n",
    "\n",
    "# choose vars needed for calculation\n",
    "# set important indexes\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893       (51.5, 64.0]\n",
       "2895       (51.5, 64.0]\n",
       "5619     (80.88, 337.0]\n",
       "5621     (80.88, 337.0]\n",
       "5645       (51.5, 64.0]\n",
       "5647       (51.5, 64.0]\n",
       "5667       (51.5, 64.0]\n",
       "5669       (51.5, 64.0]\n",
       "5686     (14.999, 39.0]\n",
       "5688     (14.999, 39.0]\n",
       "5876      (64.0, 80.88]\n",
       "5878      (64.0, 80.88]\n",
       "5986      (64.0, 80.88]\n",
       "5988      (64.0, 80.88]\n",
       "6367     (80.88, 337.0]\n",
       "6369     (80.88, 337.0]\n",
       "7342       (51.5, 64.0]\n",
       "7344       (51.5, 64.0]\n",
       "7479       (51.5, 64.0]\n",
       "7481       (51.5, 64.0]\n",
       "8171       (51.5, 64.0]\n",
       "8211     (14.999, 39.0]\n",
       "8213       (39.0, 51.5]\n",
       "8233       (39.0, 51.5]\n",
       "8235     (80.88, 337.0]\n",
       "8239     (14.999, 39.0]\n",
       "8244      (64.0, 80.88]\n",
       "8246       (51.5, 64.0]\n",
       "8250      (64.0, 80.88]\n",
       "8254       (51.5, 64.0]\n",
       "              ...      \n",
       "70452    (14.999, 39.0]\n",
       "70453      (39.0, 51.5]\n",
       "70454      (51.5, 64.0]\n",
       "70455      (39.0, 51.5]\n",
       "70456     (64.0, 80.88]\n",
       "70457      (51.5, 64.0]\n",
       "70458      (39.0, 51.5]\n",
       "70459      (51.5, 64.0]\n",
       "70460    (14.999, 39.0]\n",
       "70461    (80.88, 337.0]\n",
       "70462      (39.0, 51.5]\n",
       "70463     (64.0, 80.88]\n",
       "70464      (39.0, 51.5]\n",
       "70465      (39.0, 51.5]\n",
       "70466      (51.5, 64.0]\n",
       "70467    (80.88, 337.0]\n",
       "70468    (80.88, 337.0]\n",
       "70469     (64.0, 80.88]\n",
       "70470    (14.999, 39.0]\n",
       "70472      (51.5, 64.0]\n",
       "70473    (14.999, 39.0]\n",
       "70474    (80.88, 337.0]\n",
       "70475     (64.0, 80.88]\n",
       "70476      (51.5, 64.0]\n",
       "70477      (51.5, 64.0]\n",
       "70478      (39.0, 51.5]\n",
       "70479    (80.88, 337.0]\n",
       "70480    (14.999, 39.0]\n",
       "70481    (14.999, 39.0]\n",
       "70482    (14.999, 39.0]\n",
       "Name: sqm_bin, Length: 5099, dtype: category\n",
       "Categories (5, interval[float64]): [(14.999, 39.0] < (39.0, 51.5] < (51.5, 64.0] < (64.0, 80.88] < (80.88, 337.0]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sqm_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "## Define functions that will be used in lambda functions for a dataset\n",
    "#######################################################################\n",
    "\n",
    "# Expanding window mean for a variable\n",
    "def expanding_mean_for_var(row,var_to_calc,historic_df):\n",
    "    var = historic_df[\n",
    "        (historic_df.index.get_level_values('published_dt') < row.name)\n",
    "    ][var_to_calc].mean()\n",
    "    return var\n",
    "\n",
    "# Expanding window mean for a variable in a group\n",
    "def expanding_mean_for_var_per_group(row,var_to_calc,historic_df,group):\n",
    "    var = historic_df[\n",
    "        (historic_df.index.get_level_values('published_dt') < row.name)\n",
    "        & (historic_df.index.get_level_values('area_from_geo') == row.name[1])\n",
    "    ][var_to_calc].mean()\n",
    "    return var\n",
    "\n",
    "\n",
    "def rolling_mean_for_var(row,var_to_calc,historic_df,days):\n",
    "    var = historic_df[\n",
    "       (historic_df.index.get_level_values('published_dt') < row.name)\n",
    "       & (historic_df.index.get_level_values('published_dt') > (row.name - pd.to_timedelta(days, unit='d')))\n",
    "    ][var_to_calc].mean()\n",
    "    return var\n",
    "\n",
    "\n",
    "# Rolling window mean for a variable in a group\n",
    "def rolling_mean_for_var_per_group(row,var_to_calc,historic_df,group,days):\n",
    "    var = historic_df[\n",
    "        (historic_df.index.get_level_values('published_dt') < row.name[0])\n",
    "       & (historic_df.index.get_level_values('published_dt') > (row.name[0] - pd.to_timedelta(days, unit='d')))\n",
    "        & (historic_df.index.get_level_values(group) == row.name[1])\n",
    "    ][var_to_calc].mean()\n",
    "    return var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate variables without group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 21.071618 sec\n"
     ]
    }
   ],
   "source": [
    "# Setup new dataset for purpose\n",
    "df_no_group = data[['uuid','published_dt','sqm_sold_price','sqm_price_diff','living_area','sqm_rent_price']].copy()\n",
    "df_no_group = df_no_group.set_index('published_dt')\n",
    "\n",
    "before = datetime.now()\n",
    "rolling_mean_sqm_price_90d = df_no_group.apply(lambda row: rolling_mean_for_var(row=row,var_to_calc='sqm_sold_price',historic_df=df_no_group,days=90),axis=1)\n",
    "rolling_mean_sqm_price_diff_90d = df_no_group.apply(lambda row: rolling_mean_for_var(row=row,var_to_calc='sqm_price_diff',historic_df=df_no_group,days=90),axis=1)\n",
    "rolling_mean_sqm_90d = df_no_group.apply(lambda row: rolling_mean_for_var(row=row,var_to_calc='living_area',historic_df=df_no_group,days=90),axis=1)\n",
    "rolling_mean_sqm_rent_90d = df_no_group.apply(lambda row: rolling_mean_for_var(row=row,var_to_calc='sqm_rent_price',historic_df=df_no_group,days=90),axis=1)\n",
    "\n",
    "after = datetime.now()\n",
    "print(\"run time: \"+str((after-before).total_seconds()) + \" sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate variables with groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 27.438861 sec\n"
     ]
    }
   ],
   "source": [
    "## AREA FROM GEO\n",
    "# Setup new dataset for purpose\n",
    "df_group_area = data[['uuid','published_dt','sqm_sold_price','sqm_price_diff','living_area','sqm_rent_price','area_from_geo']].copy()\n",
    "df_group_area = df_group_area.set_index(['published_dt','area_from_geo'])\n",
    "\n",
    "# only calculate for apts where more than top 20% apts in area\n",
    "geo_cnt_limit = 0.05*max(df_group_area.groupby('area_from_geo').sqm_sold_price.transform(len))\n",
    "df_group_area = df_group_area[df_group_area.groupby('area_from_geo').sqm_sold_price.transform(len) > geo_cnt_limit]\n",
    "\n",
    "before = datetime.now()\n",
    "df_group_area['rolling_mean_sqm_price_per_area_90d'] = df_group_area.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_sold_price',historic_df=df_group_area,group='area_from_geo',days=90),axis=1)\n",
    "df_group_area['rolling_mean_sqm_price_diff_per_area_90d'] = df_group_area.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_price_diff',historic_df=df_group_area,group='area_from_geo',days=90),axis=1)\n",
    "df_group_area['rolling_mean_sqm_per_area_90d'] = df_group_area.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='living_area',historic_df=df_group_area,group='area_from_geo',days=90),axis=1)\n",
    "df_group_area['rolling_mean_sqm_rent_per_area_90d'] = df_group_area.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_rent_price',historic_df=df_group_area,group='area_from_geo',days=90),axis=1)\n",
    "\n",
    "df_group_area = df_group_area.reset_index(drop=True)[['uuid','rolling_mean_sqm_price_per_area_90d','rolling_mean_sqm_price_diff_per_area_90d','rolling_mean_sqm_per_area_90d','rolling_mean_sqm_rent_per_area_90d']]\n",
    "df_group_area = df_group_area.set_index('uuid')\n",
    "after = datetime.now()\n",
    "print(\"run time: \"+str((after-before).total_seconds()) + \" sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 31.122134 sec\n"
     ]
    }
   ],
   "source": [
    "## SQM BIN\n",
    "# Setup new dataset for purpose\n",
    "df_group_sqm_bin = data[['uuid','published_dt','sqm_sold_price','sqm_price_diff','living_area','sqm_rent_price','sqm_bin']].copy()\n",
    "df_group_sqm_bin = df_group_sqm_bin.set_index(['published_dt','sqm_bin'])\n",
    "\n",
    "# only calculate for apts where more than top 20% apts in area\n",
    "geo_cnt_limit = 0.05*max(df_group_sqm_bin.groupby('sqm_bin').sqm_sold_price.transform(len))\n",
    "df_group_sqm_bin = df_group_sqm_bin[df_group_sqm_bin.groupby('sqm_bin').sqm_sold_price.transform(len) > geo_cnt_limit]\n",
    "\n",
    "before = datetime.now()\n",
    "df_group_sqm_bin['rolling_mean_sqm_price_per_sqm_bin_90d'] = df_group_sqm_bin.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_sold_price',historic_df=df_group_sqm_bin,group='sqm_bin',days=90),axis=1)\n",
    "df_group_sqm_bin['rolling_mean_sqm_price_diff_per_sqm_bin_90d'] = df_group_sqm_bin.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_price_diff',historic_df=df_group_sqm_bin,group='sqm_bin',days=90),axis=1)\n",
    "df_group_sqm_bin['rolling_mean_sqm_per_sqm_bin_90d'] = df_group_sqm_bin.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='living_area',historic_df=df_group_sqm_bin,group='sqm_bin',days=90),axis=1)\n",
    "df_group_sqm_bin['rolling_mean_sqm_rent_sqm_bin_90d'] = df_group_sqm_bin.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_rent_price',historic_df=df_group_sqm_bin,group='sqm_bin',days=90),axis=1)\n",
    "\n",
    "df_group_sqm_bin = df_group_sqm_bin.reset_index(drop=True)[['uuid','rolling_mean_sqm_price_per_sqm_bin_90d','rolling_mean_sqm_price_diff_per_sqm_bin_90d','rolling_mean_sqm_per_sqm_bin_90d','rolling_mean_sqm_rent_sqm_bin_90d']]\n",
    "df_group_sqm_bin = df_group_sqm_bin.set_index('uuid')\n",
    "after = datetime.now()\n",
    "print(\"run time: \"+str((after-before).total_seconds()) + \" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time: 29.91754 sec\n"
     ]
    }
   ],
   "source": [
    "## BROKER\n",
    "# Setup new dataset for purpose\n",
    "df_group_broker = data[['uuid','published_dt','sqm_sold_price','sqm_price_diff','living_area','sqm_rent_price','source_name']].copy()\n",
    "df_group_broker = df_group_broker.set_index(['published_dt','source_name'])\n",
    "\n",
    "# only calculate for apts where more than top 20% apts in area\n",
    "geo_cnt_limit = 0.05*max(df_group_broker.groupby('source_name').sqm_sold_price.transform(len))\n",
    "df_group_broker = df_group_broker[df_group_broker.groupby('source_name').sqm_sold_price.transform(len) > geo_cnt_limit]\n",
    "\n",
    "before = datetime.now()\n",
    "df_group_broker['rolling_mean_sqm_price_per_broker_90d'] = df_group_broker.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_sold_price',historic_df=df_group_broker,group='source_name',days=90),axis=1)\n",
    "df_group_broker['rolling_mean_sqm_price_diff_per_broker_90d'] = df_group_broker.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_price_diff',historic_df=df_group_broker,group='source_name',days=90),axis=1)\n",
    "df_group_broker['rolling_mean_sqm_per_broker_90d'] = df_group_broker.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='living_area',historic_df=df_group_broker,group='source_name',days=90),axis=1)\n",
    "df_group_broker['rolling_mean_sqm_rent_per_broker_90d'] = df_group_broker.apply(lambda row: rolling_mean_for_var_per_group(row=row,var_to_calc='sqm_rent_price',historic_df=df_group_broker,group='source_name',days=90),axis=1)\n",
    "\n",
    "df_group_broker = df_group_broker.reset_index(drop=True)[['uuid','rolling_mean_sqm_price_per_broker_90d','rolling_mean_sqm_price_diff_per_broker_90d','rolling_mean_sqm_per_broker_90d','rolling_mean_sqm_rent_per_broker_90d']]\n",
    "df_group_broker = df_group_broker.set_index('uuid')\n",
    "after = datetime.now()\n",
    "print(\"run time: \"+str((after-before).total_seconds()) + \" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data.copy()\n",
    "output = pd.merge(output,df_group_area,left_on = 'uuid', right_index = True, how = 'left')\n",
    "output = pd.merge(output,df_group_sqm_bin,left_on = 'uuid', right_index = True, how = 'left')\n",
    "output = pd.merge(output,df_group_broker,left_on = 'uuid', right_index = True, how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.loc[data['published_dt'] >'2016-04-01'][\n",
    "    ['published_dt'\n",
    "    ,'sqm_sold_price'\n",
    "    ,'rooms'\n",
    "    ,'floor'\n",
    "    ,'rent'\n",
    "    ,'living_area'\n",
    "    ,'construction_year'\n",
    "    ,'distance_ocean'\n",
    "    ,'published_week'\n",
    "    ,'rolling_mean_sqm_price_diff_per_area_90d'\n",
    "    ,'rolling_mean_sqm_per_area_90d'\n",
    "    ,'rolling_mean_sqm_rent_per_area_90d'\n",
    "    ,'rolling_mean_sqm_price_per_sqm_bin_90d'\n",
    "    ,'rolling_mean_sqm_price_diff_per_sqm_bin_90d'\n",
    "    ,'rolling_mean_sqm_per_sqm_bin_90d'\n",
    "    ,'rolling_mean_sqm_rent_sqm_bin_90d'\n",
    "    ,'rolling_mean_sqm_price_per_broker_90d'\n",
    "    ,'rolling_mean_sqm_price_diff_per_broker_90d'\n",
    "    ,'rolling_mean_sqm_per_broker_90d'\n",
    "    ,'rolling_mean_sqm_rent_per_broker_90d'\n",
    "    ]\n",
    "]\n",
    "output.to_csv('featured_variables.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
